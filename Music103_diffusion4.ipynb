{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4glFUe2R9uRc"
   },
   "source": [
    "# Music 103 diffusion version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-iydqiNU5fGu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from os.path import exists\n",
    "from os import remove, chdir\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-J1xVnVE_6Zm"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output\n",
    "    \n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        max_len = x.size(1)\n",
    "        pe = torch.zeros(max_len, self.d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.d_model, 2).float() * -(math.log(10000.0) / self.d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        pe = pe.unsqueeze(0).to(x.device)\n",
    "        return x + pe\n",
    "\n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x\n",
    "\n",
    "class EmbedHead(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        inner_dim_1,\n",
    "        inner_dim_2,\n",
    "        out_dim\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, inner_dim_1)\n",
    "        self.linear2 = nn.Linear(inner_dim_1, inner_dim_2)\n",
    "        self.linear3 = nn.Linear(inner_dim_2, out_dim)\n",
    "        self.activation_fn = nn.functional.gelu\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation_fn(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.activation_fn(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class EmbedFC(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim):\n",
    "        super(EmbedFC, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        layers = [\n",
    "            nn.Linear(input_dim, emb_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(emb_dim, emb_dim),\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_dim)\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder_embedding = EmbedHead(src_vocab_size + tgt_vocab_size, d_model, d_model, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "        self.time_embeddings = nn.ModuleList([EmbedFC(1, d_model) for _ in range(num_layers)])\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.output_layer = nn.Sequential(PositionWiseFeedForward(d_model, d_ff), nn.Linear(d_model, tgt_vocab_size))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, x, time):\n",
    "        embedding = self.dropout(self.positional_encoding(self.encoder_embedding(torch.cat([src, x], dim=-1))))\n",
    "\n",
    "        for i, enc_layer in enumerate(self.encoder_layers):\n",
    "            time_embedding = self.time_embeddings[i](time).unsqueeze(1)\n",
    "            embedding = enc_layer(embedding + time_embedding, None)\n",
    "        \n",
    "        output = self.output_layer(embedding)\n",
    "        \n",
    "        return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQVAE(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_heads, num_layers, d_ff, dropout, codebook_size, d_codebook):\n",
    "        super().__init__()\n",
    "        self.encoder_embedding = EmbedHead(vocab_size, d_model, d_model, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.encoder_output = nn.Linear(d_model, d_codebook)\n",
    "        self.codebook = nn.Embedding(codebook_size, d_codebook)\n",
    "        self.codebook.weight.data.uniform_(-1/d_codebook, 1/d_codebook)\n",
    "        self.decoder_embedding = EmbedHead(d_codebook, d_model, d_model, d_model)\n",
    "        self.decoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_output = nn.Linear(d_model, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def encode(self, x):\n",
    "        embedding = self.dropout(self.positional_encoding(self.encoder_embedding(x)))\n",
    "        for i, enc_layer in enumerate(self.encoder_layers):\n",
    "            embedding = enc_layer(embedding, None)\n",
    "        return self.encoder_output(embedding)\n",
    "    \n",
    "    def vq(self, z):\n",
    "        # z: [batch_size, seq_length, d_codebook]\n",
    "        distance = (z.unsqueeze(2) - self.codebook.weight.unsqueeze(0).unsqueeze(0)).pow(2).mean(dim=-1)\n",
    "        _, indices = torch.min(distance, dim=-1)\n",
    "        return self.codebook(indices)\n",
    "\n",
    "    def decode(self, z):\n",
    "        embedding = self.dropout(self.positional_encoding(self.decoder_embedding(z)))\n",
    "        for i, dec_layer in enumerate(self.decoder_layers):\n",
    "            embedding = dec_layer(embedding, None)\n",
    "        return torch.sigmoid(self.decoder_output(embedding))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_length, vocab_size]\n",
    "        z = self.encode(x)\n",
    "        z_vq = self.vq(z)\n",
    "        z_straight_through = (z_vq - z).detach() + z\n",
    "        x_recon = self.decode(z_straight_through)\n",
    "        recon_loss = nn.functional.mse_loss(x_recon, x)\n",
    "        embed_loss = nn.functional.mse_loss(z_vq, z.detach())\n",
    "        commit_loss = nn.functional.mse_loss(z, z_vq.detach())\n",
    "        return x_recon, recon_loss, embed_loss, commit_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_VQVAE(vqvae, optim, trainset, validset, lr, n_epoch, device, patience, alpha=0.5,beta=1):\n",
    "    wait = 0\n",
    "    min_valid_loss = float('inf')\n",
    "    for ep in tqdm(range(n_epoch)):\n",
    "        vqvae.train()\n",
    "\n",
    "        # linear lrate decay\n",
    "        optim.param_groups[0]['lr'] = lr*(1-ep/n_epoch)\n",
    "        loss_ema = None\n",
    "        # train\n",
    "        for idx, src, tgt in trainset:\n",
    "            optim.zero_grad()\n",
    "            tgt = tgt.to(device)\n",
    "            src = src.to(device)\n",
    "            _, recon_loss, embed_loss, commit_loss = vqvae(tgt)\n",
    "            loss = recon_loss + beta * embed_loss + alpha * commit_loss\n",
    "            loss.backward()\n",
    "            if loss_ema is None:\n",
    "                loss_ema = loss.item()\n",
    "            else:\n",
    "                loss_ema = 0.95 * loss_ema + 0.05 * loss.item()\n",
    "            optim.step()\n",
    "            \n",
    "        # validation\n",
    "        vqvae.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for idx, src, tgt in validset:\n",
    "                tgt = tgt.to(device)\n",
    "                src = src.to(device)\n",
    "                _, recon_loss, embed_loss, commit_loss = vqvae(tgt)\n",
    "                loss = recon_loss\n",
    "                total_loss += loss.item()\n",
    "        avg_valid_loss = total_loss / len(validset)\n",
    "\n",
    "        # early stopping\n",
    "        if avg_valid_loss < min_valid_loss:\n",
    "            min_valid_loss = avg_valid_loss\n",
    "            torch.save(vqvae.state_dict(), f\"model_best_vqvae.pt\")\n",
    "            print(f'epoch {ep}, train_loss: {loss_ema:.4f}, valid loss: {avg_valid_loss:.4f}')\n",
    "            wait = 0\n",
    "        else:\n",
    "            print(f'epoch {ep}, train_loss: {loss_ema:.4f}, valid loss: {avg_valid_loss:.4f}, min_valid_loss: {min_valid_loss:.4f}, wait: {wait} / {patience}')\n",
    "            wait += 1\n",
    "        if wait >= patience:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitted dataset found!\n"
     ]
    }
   ],
   "source": [
    "# hardcoding these here\n",
    "n_epoch = 200\n",
    "n_T = 1000\n",
    "n_feat = 128\n",
    "lr = 1e-4\n",
    "ws_test = [0.0, 0.5, 2.0]\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "src_vocab_size = 12\n",
    "tgt_vocab_size = 12\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 4\n",
    "d_ff = 4096//8\n",
    "max_seq_length = 2400\n",
    "dropout = 0.1\n",
    "batchsize = 16\n",
    "mode = \"train\"\n",
    "\n",
    "\n",
    "if exists(\"trainset_w.pkl\") and exists(\"validset_w.pkl\") and exists(\"testset_w.pkl\"):\n",
    "    print(\"splitted dataset found!\")\n",
    "    with open(\"trainset_w.pkl\", \"rb\") as f:\n",
    "        trainset = pickle.load(f)\n",
    "    with open(\"validset_w.pkl\", \"rb\") as f:\n",
    "        validset = pickle.load(f)\n",
    "    with open(\"testset_w.pkl\", \"rb\") as f:\n",
    "        testset = pickle.load(f)\n",
    "else:\n",
    "    print(\"?\")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Unpack batch into individual components\n",
    "    idx, src_data, tgt_data, w = zip(*batch)\n",
    "    #print(len(rates[0]), len(tgt_data[0]), len(src_data[0]))\n",
    "    \n",
    "    # Convert `src_data`, `tgt_data`, and `rates` to tensors if they are not already\n",
    "    src_data = [torch.tensor(s, dtype=torch.float32) if not isinstance(s, torch.Tensor) else s for s in src_data]\n",
    "    tgt_data = [torch.tensor(t, dtype=torch.float32) if not isinstance(t, torch.Tensor) else t for t in tgt_data]\n",
    "\n",
    "    src_data = [torch.cat([s], dim=-1) for s in src_data]\n",
    "    tgt_data = [torch.cat([t], dim=-1) for t in tgt_data]\n",
    "\n",
    "    # Pad src_data\n",
    "    src_data = nn.utils.rnn.pad_sequence(src_data, batch_first=True, padding_value=0.).to(DEVICE)\n",
    "\n",
    "    # Pad tgt_data\n",
    "    tgt_data = nn.utils.rnn.pad_sequence(tgt_data, batch_first=True, padding_value=0).to(DEVICE)\n",
    "\n",
    "    # Extract the last dimension and one-hot encode it\n",
    "    return idx, src_data, tgt_data\n",
    "\n",
    "\n",
    "trainset = data.DataLoader(trainset, batch_size=batchsize, collate_fn=collate_fn)\n",
    "validset = data.DataLoader(validset, batch_size=1, collate_fn=collate_fn)\n",
    "testset = data.DataLoader(testset, batch_size=1, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:10<33:41, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train_loss: 0.2664, valid loss: 0.1991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:20<33:21, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train_loss: 0.1527, valid loss: 0.1953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/200 [00:30<33:04, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train_loss: 0.1422, valid loss: 0.1941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [00:40<32:48, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train_loss: 0.1384, valid loss: 0.1934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:50<32:34, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train_loss: 0.1360, valid loss: 0.1929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [01:00<32:52, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train_loss: 0.1342, valid loss: 0.1926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 7/200 [01:10<32:36, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train_loss: 0.1328, valid loss: 0.1925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [01:21<32:35, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train_loss: 0.1316, valid loss: 0.1924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/200 [01:31<32:33, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train_loss: 0.1307, valid loss: 0.1923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [01:41<32:11, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train_loss: 0.1300, valid loss: 0.1906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/200 [01:51<32:20, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train_loss: 0.1705, valid loss: 0.1704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 12/200 [02:02<32:02, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train_loss: 0.1666, valid loss: 0.1620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 13/200 [02:12<32:10, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train_loss: 0.1797, valid loss: 0.1620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 14/200 [02:22<31:48, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train_loss: 0.1856, valid loss: 0.1540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 15/200 [02:33<31:52, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train_loss: 0.1774, valid loss: 0.1515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 16/200 [02:43<31:24, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train_loss: 0.1547, valid loss: 0.1495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 17/200 [02:53<31:02, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train_loss: 0.1414, valid loss: 0.1527, min_valid_loss: 0.1495, wait: 0 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 18/200 [03:03<30:43, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train_loss: 0.1336, valid loss: 0.1644, min_valid_loss: 0.1495, wait: 1 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [03:13<30:32, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train_loss: 0.1514, valid loss: 0.1598, min_valid_loss: 0.1495, wait: 2 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [03:23<30:12, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train_loss: 0.2388, valid loss: 0.1383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [03:33<30:05, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train_loss: 0.2488, valid loss: 0.1392, min_valid_loss: 0.1383, wait: 0 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 22/200 [03:43<29:56, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train_loss: 0.2483, valid loss: 0.1419, min_valid_loss: 0.1383, wait: 1 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 23/200 [03:53<29:37, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train_loss: 0.2466, valid loss: 0.1451, min_valid_loss: 0.1383, wait: 2 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 24/200 [04:04<30:03, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train_loss: 0.2270, valid loss: 0.1436, min_valid_loss: 0.1383, wait: 3 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 25/200 [04:14<29:37, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train_loss: 0.1812, valid loss: 0.1270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 26/200 [04:24<29:19, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train_loss: 0.1667, valid loss: 0.1245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 27/200 [04:34<29:28, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train_loss: 0.1589, valid loss: 0.1241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 28/200 [04:44<29:05, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train_loss: 0.1273, valid loss: 0.1072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 29/200 [04:54<28:56, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train_loss: 0.1054, valid loss: 0.1082, min_valid_loss: 0.1072, wait: 0 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30/200 [05:04<28:43, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train_loss: 0.0969, valid loss: 0.1053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 31/200 [05:15<28:34, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, train_loss: 0.0972, valid loss: 0.0957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 32/200 [05:25<28:15, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, train_loss: 0.0892, valid loss: 0.0953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 33/200 [05:34<27:58, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, train_loss: 0.0879, valid loss: 0.0965, min_valid_loss: 0.0953, wait: 0 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 34/200 [05:44<27:42, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, train_loss: 0.0844, valid loss: 0.1011, min_valid_loss: 0.0953, wait: 1 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 35/200 [05:55<28:04, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, train_loss: 0.0763, valid loss: 0.1026, min_valid_loss: 0.0953, wait: 2 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 36/200 [06:05<27:41, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, train_loss: 0.0770, valid loss: 0.1038, min_valid_loss: 0.0953, wait: 3 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 37/200 [06:15<27:23, 10.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, train_loss: 0.0725, valid loss: 0.1019, min_valid_loss: 0.0953, wait: 4 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 38/200 [06:25<27:13, 10.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, train_loss: 0.0721, valid loss: 0.1057, min_valid_loss: 0.0953, wait: 5 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 39/200 [06:35<27:04, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, train_loss: 0.0750, valid loss: 0.1080, min_valid_loss: 0.0953, wait: 6 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [06:45<26:48, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, train_loss: 0.0729, valid loss: 0.1010, min_valid_loss: 0.0953, wait: 7 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 41/200 [06:55<26:35, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, train_loss: 0.0703, valid loss: 0.0952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 42/200 [07:05<26:30, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, train_loss: 0.0753, valid loss: 0.1028, min_valid_loss: 0.0952, wait: 0 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 43/200 [07:17<27:31, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, train_loss: 0.0677, valid loss: 0.1071, min_valid_loss: 0.0952, wait: 1 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 44/200 [07:27<26:55, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, train_loss: 0.0694, valid loss: 0.1071, min_valid_loss: 0.0952, wait: 2 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 45/200 [07:37<26:56, 10.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, train_loss: 0.0678, valid loss: 0.1093, min_valid_loss: 0.0952, wait: 3 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 46/200 [07:47<26:24, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, train_loss: 0.0669, valid loss: 0.1099, min_valid_loss: 0.0952, wait: 4 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 47/200 [07:57<25:50, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, train_loss: 0.0668, valid loss: 0.1086, min_valid_loss: 0.0952, wait: 5 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 48/200 [08:07<25:24, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, train_loss: 0.0650, valid loss: 0.1106, min_valid_loss: 0.0952, wait: 6 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 49/200 [08:17<25:06,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, train_loss: 0.0585, valid loss: 0.1065, min_valid_loss: 0.0952, wait: 7 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 50/200 [08:27<24:46,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, train_loss: 0.0508, valid loss: 0.1033, min_valid_loss: 0.0952, wait: 8 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 51/200 [08:36<24:30,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50, train_loss: 0.0517, valid loss: 0.1032, min_valid_loss: 0.0952, wait: 9 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 52/200 [08:47<24:36,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51, train_loss: 0.0492, valid loss: 0.1075, min_valid_loss: 0.0952, wait: 10 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 53/200 [08:56<24:17,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52, train_loss: 0.0483, valid loss: 0.0975, min_valid_loss: 0.0952, wait: 11 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 54/200 [09:06<24:04,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53, train_loss: 0.0504, valid loss: 0.0950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 55/200 [09:16<23:56,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54, train_loss: 0.0452, valid loss: 0.0971, min_valid_loss: 0.0950, wait: 0 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 56/200 [09:26<23:48,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55, train_loss: 0.0446, valid loss: 0.0955, min_valid_loss: 0.0950, wait: 1 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 57/200 [09:36<23:40,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56, train_loss: 0.0403, valid loss: 0.0917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 58/200 [09:46<23:46, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57, train_loss: 0.0425, valid loss: 0.0936, min_valid_loss: 0.0917, wait: 0 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 59/200 [09:57<23:53, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58, train_loss: 0.0418, valid loss: 0.0959, min_valid_loss: 0.0917, wait: 1 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 60/200 [10:07<23:45, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59, train_loss: 0.0407, valid loss: 0.0936, min_valid_loss: 0.0917, wait: 2 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 61/200 [10:17<23:45, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60, train_loss: 0.0411, valid loss: 0.0938, min_valid_loss: 0.0917, wait: 3 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 62/200 [10:28<23:31, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61, train_loss: 0.0400, valid loss: 0.0959, min_valid_loss: 0.0917, wait: 4 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 63/200 [10:38<23:21, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62, train_loss: 0.0408, valid loss: 0.0990, min_valid_loss: 0.0917, wait: 5 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 64/200 [10:48<23:19, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63, train_loss: 0.0423, valid loss: 0.0988, min_valid_loss: 0.0917, wait: 6 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 65/200 [10:58<23:03, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64, train_loss: 0.0423, valid loss: 0.0995, min_valid_loss: 0.0917, wait: 7 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 66/200 [11:09<22:49, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65, train_loss: 0.0432, valid loss: 0.0975, min_valid_loss: 0.0917, wait: 8 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 67/200 [11:19<22:38, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66, train_loss: 0.0430, valid loss: 0.0963, min_valid_loss: 0.0917, wait: 9 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 68/200 [11:29<22:25, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67, train_loss: 0.0419, valid loss: 0.0961, min_valid_loss: 0.0917, wait: 10 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 69/200 [11:39<22:27, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68, train_loss: 0.0449, valid loss: 0.1023, min_valid_loss: 0.0917, wait: 11 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 70/200 [11:50<22:11, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69, train_loss: 0.0453, valid loss: 0.0998, min_valid_loss: 0.0917, wait: 12 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 71/200 [12:00<22:02, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70, train_loss: 0.0450, valid loss: 0.0958, min_valid_loss: 0.0917, wait: 13 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 72/200 [12:10<21:47, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71, train_loss: 0.0433, valid loss: 0.0913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 73/200 [12:20<21:44, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72, train_loss: 0.0433, valid loss: 0.0932, min_valid_loss: 0.0913, wait: 0 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 74/200 [12:31<21:40, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73, train_loss: 0.0393, valid loss: 0.0949, min_valid_loss: 0.0913, wait: 1 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 75/200 [12:42<21:45, 10.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74, train_loss: 0.0402, valid loss: 0.0981, min_valid_loss: 0.0913, wait: 2 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 76/200 [12:52<21:32, 10.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75, train_loss: 0.0378, valid loss: 0.0957, min_valid_loss: 0.0913, wait: 3 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 77/200 [13:03<21:28, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76, train_loss: 0.0372, valid loss: 0.0980, min_valid_loss: 0.0913, wait: 4 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 78/200 [13:13<21:13, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77, train_loss: 0.0371, valid loss: 0.0961, min_valid_loss: 0.0913, wait: 5 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 79/200 [13:23<21:04, 10.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78, train_loss: 0.0364, valid loss: 0.0991, min_valid_loss: 0.0913, wait: 6 / 20\n"
     ]
    }
   ],
   "source": [
    "vqvae = VQVAE(tgt_vocab_size, d_model, num_heads, 1, d_ff, dropout, 256, 12).to(DEVICE)\n",
    "optim = torch.optim.Adam(vqvae.parameters(), lr=lr)\n",
    "train_VQVAE(vqvae, optim, trainset, validset, lr, n_epoch, DEVICE, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_vqvae(vqvae, checkpoint, testset):\n",
    "    vqvae.load_state_dict(torch.load(checkpoint))\n",
    "    vqvae.eval()\n",
    "    x_gens = []\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, src, tgt in tqdm(testset, total=len(testset)):\n",
    "            if count > 3:\n",
    "                break\n",
    "            x_gen, _, _, _ = vqvae(tgt)\n",
    "            print(x_gen)\n",
    "            x_gen = (x_gen >= torch.quantile(x_gen, 0.66, dim=-1, keepdim=True)).long()\n",
    "            \n",
    "            x_gens.append((idx, x_gen))\n",
    "            count += 1\n",
    "\n",
    "    torch.save(x_gens, \"song_test_music103.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:00<00:02, 45.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1133, 0.1141, 0.0905,  ..., 0.0930, 0.0840, 0.1269],\n",
      "         [0.1173, 0.1253, 0.0941,  ..., 0.1006, 0.0864, 0.1244],\n",
      "         [0.1398, 0.1426, 0.1165,  ..., 0.1231, 0.1110, 0.1434],\n",
      "         ...,\n",
      "         [0.0379, 0.0384, 0.0307,  ..., 0.0345, 0.0251, 0.0398],\n",
      "         [0.0400, 0.0372, 0.0323,  ..., 0.0339, 0.0257, 0.0404],\n",
      "         [0.0420, 0.0360, 0.0330,  ..., 0.0323, 0.0260, 0.0412]]])\n",
      "tensor([[[0.1137, 0.1135, 0.0914,  ..., 0.0937, 0.0842, 0.1270],\n",
      "         [0.1177, 0.1246, 0.0951,  ..., 0.1013, 0.0866, 0.1245],\n",
      "         [0.1403, 0.1419, 0.1178,  ..., 0.1241, 0.1114, 0.1437],\n",
      "         ...,\n",
      "         [0.0376, 0.0361, 0.0275,  ..., 0.0345, 0.0242, 0.0386],\n",
      "         [0.0379, 0.0356, 0.0278,  ..., 0.0329, 0.0248, 0.0388],\n",
      "         [0.0376, 0.0357, 0.0279,  ..., 0.0312, 0.0249, 0.0392]]])\n",
      "tensor([[[0.1456, 0.1365, 0.1331,  ..., 0.1405, 0.1132, 0.1604],\n",
      "         [0.1503, 0.1469, 0.1378,  ..., 0.1503, 0.1164, 0.1581],\n",
      "         [0.1683, 0.1581, 0.1584,  ..., 0.1675, 0.1398, 0.1726],\n",
      "         ...,\n",
      "         [0.1403, 0.1229, 0.1554,  ..., 0.1531, 0.1208, 0.1503],\n",
      "         [0.1313, 0.1159, 0.1499,  ..., 0.1523, 0.1181, 0.1496],\n",
      "         [0.1227, 0.1128, 0.1424,  ..., 0.1465, 0.1162, 0.1470]]])\n",
      "tensor([[[0.1481, 0.1380, 0.1352,  ..., 0.1438, 0.1154, 0.1627],\n",
      "         [0.1528, 0.1484, 0.1399,  ..., 0.1538, 0.1185, 0.1604],\n",
      "         [0.1704, 0.1593, 0.1601,  ..., 0.1704, 0.1418, 0.1745],\n",
      "         ...,\n",
      "         [0.1664, 0.1187, 0.1401,  ..., 0.1449, 0.1357, 0.1722],\n",
      "         [0.1606, 0.1125, 0.1393,  ..., 0.1506, 0.1270, 0.1740],\n",
      "         [0.1553, 0.1127, 0.1388,  ..., 0.1560, 0.1240, 0.1729]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_vqvae(vqvae, \"model_best_vqvae.pt\", testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_5PFYwtohYY"
   },
   "source": [
    "# **1. DDPM**\n",
    "\n",
    "\n",
    "# a. Building Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yAENstIAuDh"
   },
   "source": [
    "# b. DDPM Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "16Wd4uXlAsE7"
   },
   "outputs": [],
   "source": [
    "def ddpm_schedules(beta1, beta2, T):\n",
    "    assert beta1 < beta2 < 1.0, \"beta1 and beta2 must be in (0, 1)\"\n",
    "\n",
    "    ##################\n",
    "    ### Problem 1 (a): Implement ddpm_schedules()\n",
    "    beta_t = torch.linspace(beta1, beta2, T).float()\n",
    "\n",
    "    alpha_t = 1 - beta_t\n",
    "    oneover_sqrta = 1 / torch.sqrt(alpha_t)\n",
    "    sqrt_beta_t = torch.sqrt(beta_t)\n",
    "    alphabar_t = torch.cumprod(alpha_t, dim=0)\n",
    "    sqrtab = torch.sqrt(alphabar_t)\n",
    "    sqrtmab = torch.sqrt(1 - alphabar_t)\n",
    "    mab_over_sqrtmab_inv = (1 - alpha_t) / torch.sqrt(1 - alphabar_t)\n",
    "    ##################\n",
    "    ##################\n",
    "\n",
    "    return {\n",
    "        \"alpha_t\": alpha_t,  # \\alpha_t\n",
    "        \"oneover_sqrta\": oneover_sqrta,  # 1/\\sqrt{\\alpha_t}\n",
    "        \"sqrt_beta_t\": sqrt_beta_t,  # \\sqrt{\\beta_t}\n",
    "        \"alphabar_t\": alphabar_t,  # \\bar{\\alpha_t}\n",
    "        \"sqrtab\": sqrtab,  # \\sqrt{\\bar{\\alpha_t}}\n",
    "        \"sqrtmab\": sqrtmab,  # \\sqrt{1-\\bar{\\alpha_t}}\n",
    "        \"mab_over_sqrtmab\": mab_over_sqrtmab_inv,  # (1-\\alpha_t)/\\sqrt{1-\\bar{\\alpha_t}}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeL8cLF-A9u-"
   },
   "source": [
    "# c. DDPM Main Module\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the noise $\\sigma_t^2=\\beta_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "BQb0JijTA9CQ"
   },
   "outputs": [],
   "source": [
    "class DDPM(nn.Module):\n",
    "    def __init__(self, nn_model, betas, n_T, device, n_inference=None, drop_prob=0.1):\n",
    "        super(DDPM, self).__init__()\n",
    "        self.nn_model = nn_model.to(device)\n",
    "\n",
    "        for k, v in ddpm_schedules(betas[0], betas[1], n_T).items():\n",
    "            self.register_buffer(k, v)\n",
    "        \n",
    "        self.n_T = n_T\n",
    "        self.n_inference = n_inference if n_inference else n_T \n",
    "        \n",
    "        for k, v in ddpm_schedules(betas[0], betas[1], self.n_inference).items():\n",
    "            self.register_buffer(k+'_KAIMING', v)\n",
    "\n",
    "        self.device = device\n",
    "        self.drop_prob = drop_prob\n",
    "        self.loss_mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        ##################\n",
    "        ### Problem 1 (b): Implement forward()\n",
    "        t = torch.randint(0, self.n_T, (tgt.size(0),), device=self.device)\n",
    "        sqrtab_t, sqrtmab_t = self.sqrtab[t].view(-1, 1, 1), \\\n",
    "            self.sqrtmab[t].view(-1, 1, 1)\n",
    "\n",
    "        noise = torch.randn_like(tgt).to(self.device)  # Define noise tensor\n",
    "        x_t = sqrtab_t * tgt + sqrtmab_t * noise\n",
    "\n",
    "        # mask out with probability\n",
    "        # context_mask = torch.bernoulli(torch.zeros(src.shape[0])+self.drop_prob).unsqueeze(-1).unsqueeze(-1).to(self.device)\n",
    "\n",
    "        pred_noise = self.nn_model(src, x_t, t / (self.n_T - 1))\n",
    "        loss = self.loss_mse(pred_noise, noise) \n",
    "        ##################\n",
    "        ##################\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, src, guide_w=0.0):\n",
    "        n_sample = src.shape[0]\n",
    "        x_i = torch.randn(*src.shape).to(self.device)\n",
    "\n",
    "        for i in range(int(self.n_inference), 0, -1):\n",
    "\n",
    "            ##################\n",
    "            ### Problem 1 (c): Implement sample()\n",
    "            t = torch.full((n_sample,), (i - 1) / (self.n_inference - 1)).to(self.device).float()\n",
    "            t_i = t.view(-1, 1, 1)\n",
    "\n",
    "            # double batch\n",
    "\n",
    "            z = torch.randn(*src.shape).to(self.device) if i > 1 else 0 # if last step, no noise\n",
    "            # classifier-free guidance\n",
    "            pred_full = self.nn_model(src, x_i, t_i)\n",
    "            x_i = self.oneover_sqrta_KAIMING[i - 1] * (x_i - pred_full * self.mab_over_sqrtmab_KAIMING[i - 1])\\\n",
    "                + self.sqrt_beta_t_KAIMING[i - 1] * z\n",
    "        return x_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYUg7AjHottB"
   },
   "source": [
    "# c. Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "hrG8n5WJAo51"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_main_loop(ddpm, optim, trainset, validset, testset, lr, n_epoch, device, guide_w, patience):\n",
    "    wait = 0\n",
    "    min_valid_loss = float('inf')\n",
    "    for ep in tqdm(range(n_epoch)):\n",
    "        ddpm.train()\n",
    "\n",
    "        # linear lrate decay\n",
    "        optim.param_groups[0]['lr'] = lr*(1-ep/n_epoch)\n",
    "        loss_ema = None\n",
    "        # train\n",
    "        for idx, src, tgt in trainset:\n",
    "            optim.zero_grad()\n",
    "            tgt = tgt.to(device)\n",
    "            src = src.to(device)\n",
    "            loss = ddpm(src, tgt)\n",
    "            loss.backward()\n",
    "            if loss_ema is None:\n",
    "                loss_ema = loss.item()\n",
    "            else:\n",
    "                loss_ema = 0.95 * loss_ema + 0.05 * loss.item()\n",
    "            optim.step()\n",
    "            \n",
    "        # validation\n",
    "        ddpm.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for idx, src, tgt in validset:\n",
    "                tgt = tgt.to(device)\n",
    "                src = src.to(device)\n",
    "                loss = ddpm(src, tgt)\n",
    "                total_loss += loss.item()\n",
    "        avg_valid_loss = total_loss / len(validset)\n",
    "\n",
    "        # early stopping\n",
    "        if avg_valid_loss < min_valid_loss:\n",
    "            min_valid_loss = avg_valid_loss\n",
    "            torch.save(ddpm.nn_model.state_dict(), f\"model_best_diffusion.pt\")\n",
    "            print(f'epoch {ep}, train_loss: {loss_ema:.4f}, valid loss: {avg_valid_loss:.4f}')\n",
    "            wait = 0\n",
    "        else:\n",
    "            print(f'epoch {ep}, train_loss: {loss_ema:.4f}, valid loss: {avg_valid_loss:.4f}, min_valid_loss: {min_valid_loss:.4f}, wait: {wait} / {patience}')\n",
    "            wait += 1\n",
    "        if wait >= patience:\n",
    "            break\n",
    "\n",
    "    # # eval\n",
    "    # ddpm.eval()\n",
    "    # x_gens = []\n",
    "    # count = 0\n",
    "    # with torch.no_grad():\n",
    "    #     for idx, src, tgt in tqdm(testset, total=len(testset)):\n",
    "    #         if count > 3:\n",
    "    #             break\n",
    "    #         x_gens.append((idx, (ddpm.sample(src, guide_w) >= 0.5).long()))\n",
    "    #         count += 1\n",
    "\n",
    "    # torch.save(x_gens, \"song_test_music103.pt\")\n",
    "\n",
    "def eval_main_loop(ddpm, checkpoint, testset, device, guide_w, rate=0.5):\n",
    "    ddpm.nn_model.load_state_dict(torch.load(checkpoint))\n",
    "    ddpm.eval()\n",
    "    x_gens = []\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, src, tgt in tqdm(testset, total=len(testset)):\n",
    "            if count > 3:\n",
    "                break\n",
    "            x_gen = ddpm.sample(src, guide_w)\n",
    "            x_gen = ((x_gen >= torch.quantile(x_gen, 0.66, dim=-1, keepdim=True)) & (x_gen >= rate)).long()\n",
    "            x_gens.append((idx, x_gen))\n",
    "            count += 1\n",
    "\n",
    "    torch.save(x_gens, \"song_test_music103.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Il39DdgeBPKc"
   },
   "source": [
    "# e. Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitted dataset found!\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "L1-Pnrj8BTqr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:03<13:12,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train_loss: 0.7961, valid loss: 0.4862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:07<13:09,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train_loss: 0.2770, valid loss: 0.1736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/200 [00:11<13:05,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train_loss: 0.1961, valid loss: 0.1186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [00:15<13:01,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train_loss: 0.1822, valid loss: 0.1173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:19<12:54,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train_loss: 0.1443, valid loss: 0.1291, min_valid_loss: 0.1173, wait: 0 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [00:23<12:47,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train_loss: 0.1629, valid loss: 0.1384, min_valid_loss: 0.1173, wait: 1 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 7/200 [00:27<12:42,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train_loss: 0.1139, valid loss: 0.1499, min_valid_loss: 0.1173, wait: 2 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [00:31<12:41,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train_loss: 0.1186, valid loss: 0.0975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/200 [00:35<12:35,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train_loss: 0.1358, valid loss: 0.1037, min_valid_loss: 0.0975, wait: 0 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [00:39<12:31,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train_loss: 0.1357, valid loss: 0.1358, min_valid_loss: 0.0975, wait: 1 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/200 [00:43<12:29,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train_loss: 0.0975, valid loss: 0.0846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 12/200 [00:47<12:27,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train_loss: 0.0953, valid loss: 0.0795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 13/200 [00:51<12:22,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train_loss: 0.0891, valid loss: 0.1167, min_valid_loss: 0.0795, wait: 0 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 14/200 [00:55<12:16,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train_loss: 0.0764, valid loss: 0.0943, min_valid_loss: 0.0795, wait: 1 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 15/200 [00:59<12:16,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train_loss: 0.0756, valid loss: 0.1029, min_valid_loss: 0.0795, wait: 2 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 16/200 [01:03<12:14,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train_loss: 0.0921, valid loss: 0.0758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 17/200 [01:07<12:08,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train_loss: 0.0868, valid loss: 0.0844, min_valid_loss: 0.0758, wait: 0 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 18/200 [01:11<12:02,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train_loss: 0.0673, valid loss: 0.0866, min_valid_loss: 0.0758, wait: 1 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [01:15<11:56,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train_loss: 0.0808, valid loss: 0.0853, min_valid_loss: 0.0758, wait: 2 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [01:19<11:54,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train_loss: 0.0734, valid loss: 0.0664\n"
     ]
    }
   ],
   "source": [
    "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout).to(DEVICE)\n",
    "ddpm = DDPM(nn_model=transformer, betas=(1e-4, 0.02), n_T=n_T, \\\n",
    "    device=DEVICE, n_inference=1000, drop_prob=0.1)\n",
    "ddpm.to(DEVICE)\n",
    "optim = torch.optim.Adam(ddpm.parameters(), lr=lr)\n",
    "train_main_loop(ddpm, optim, trainset, validset, testset, lr, n_epoch, DEVICE, 0, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:19<07:57,  4.98s/it]\n"
     ]
    }
   ],
   "source": [
    "eval_main_loop(ddpm, \"model_best_diffusion.pt\", testset, DEVICE, 0.1, 0.5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deepml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
